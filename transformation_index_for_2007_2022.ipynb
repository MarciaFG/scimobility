{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM/sRKrOrAIaAQlNo8daHCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarciaFG/scimobility/blob/main/transformation_index_for_2007_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformative Flows Project (2007-2022)**\n",
        "**Author:** Marcia R. Ferreira (Complexity Science Hub Vienna & TU Wien)\n",
        "- **Inputs:** \n",
        "\n",
        "1.   CWTS SQL Server [dimensions_2022jun]:\n",
        "\n",
        "\n",
        "      *   Exported File:\n",
        "      *   Exported File:\n",
        "\n",
        "\n",
        "2.   CWTS Publication-level classification system: Meso-fields level [dimensions_2022jun_classification]\n",
        "3.   Dimension reduction-based clustering: Laplacian matrix contructed from meso-field level topic matrix and second eigenvector of the matrix\n",
        "4.   Dimensions database on BigQuery\n",
        "\n",
        "\n",
        "- **Outputs:**"
      ],
      "metadata": {
        "id": "y-DzlwsCdcsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization and drivers"
      ],
      "metadata": {
        "id": "vHLeNDGsdvjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-Ue500cAdbLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ba9de8-6a9c-455d-a097-ea8f18b47143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 13 08:08:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    43W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "#!pip install psutil\n",
        "#!pip install humanize\n",
        "#!pip install pynput\n",
        "#pip install plotly==5.4.0\n",
        "#!pip install patool\n",
        "\n",
        "# main libraries\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import torch\n",
        "import nltk\n",
        "import GPUtil as GPU\n",
        "\n",
        "# plotting\n",
        "import plotly.graph_objs as go\n",
        "import plotly.io as pio\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.colab import files\n",
        "%load_ext google.colab.data_table\n",
        "%load_ext google.cloud.bigquery\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wQDQL_QEd3xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d341c2f-0536-4c41-b744-96bf15723bce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.9/dist-packages (1.4.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide your credentials to the runtime\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "# declare your project \n",
        "project_id = \"cshdimensionstest\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fJiI8ij1Wyx",
        "outputId": "68526942-cde7-409e-9997-ec161dd6bcf1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data imports"
      ],
      "metadata": {
        "id": "g44G5rvngOrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" NOT RUN\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1wCFzWEAwBqH47qGQG1_-G6wPgrrs03A6'\n",
        "print(id) # Verify that you have everything\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('second_eigenvector_clustering.csv')  \n",
        "clusters = pd.read_csv('second_eigenvector_clustering.csv', sep=\",\", index_col=0) # Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "print(clusters.head(10))\n",
        "print(\"The data types are as follows:\\n\", clusters.dtypes)\n",
        "print(\"The type of object is:\\n\", type(clusters))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mF7pLxCkfsZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" NOT RUN\n",
        "# unzip the files exported from SQL Server\n",
        "#!unzip \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\"\n",
        "#!unzip \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\" > /dev/null\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qwu5HLlzYbTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import patoolib\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Path of the zip file in Google Drive\n",
        "zip_path = \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\"\n",
        "\n",
        "# Name of the CSV file(s) inside the zip\n",
        "csv_file_names = [  \"spectral_meso_clusters.csv\"\n",
        "                  , \"for_division_labels.csv\"\n",
        "                  , \"grid_ranks.csv\"\n",
        "                  , \"trajectories_au_fourfive_skill.csv\"\n",
        "                  , \"trajectories_au_morethanfive_skill.csv\"\n",
        "                  , \"trajectories_au_single_skill.csv\"\n",
        "                  , \"trajectories_au_twothree_skill.csv\"]\n",
        "\n",
        "# Separator character to use in the CSV files\n",
        "separator = \";\"\n",
        "\n",
        "# Extract the zip file to a temporary directory\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    patoolib.extract_archive(zip_path, outdir=tmpdir)\n",
        "    \n",
        "    # Load each CSV file into its own dataframe\n",
        "    dfs = []\n",
        "    for csv_file_name in csv_file_names:\n",
        "        csv_file_path = os.path.join(tmpdir, csv_file_name)\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file_path, sep=separator, encoding='utf-8', header= None, decimal=\".\")\n",
        "            dfs.append(df)\n",
        "        except pd.errors.ParserError:\n",
        "            print(f\"Error loading {csv_file_name}: Skipping...\")\n",
        "\n",
        "# Print the first few rows of each dataframe\n",
        "for i, df in enumerate(dfs):\n",
        "    print(f\"Dataframe {i}:\")\n",
        "    print(df.head(2))\n",
        "print(\"###########################################\")\n",
        "\n",
        "# extract the datasets and store them into a pandas dataframe\n",
        "spectral_meso_clusters = dfs[0]\n",
        "for_division_labels = dfs[1]\n",
        "grid_ranks = dfs[2]\n",
        "trajectories_au_fourfive_skill = dfs[3]\n",
        "trajectories_au_morethanfive_skill = dfs[4]\n",
        "trajectories_au_single_skill = dfs[5]\n",
        "trajectories_au_twothree_skill = dfs[6]\n",
        "\n",
        "print(type(for_division_labels))\n",
        "print(\"###########################################\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD6eLoCry8es",
        "outputId": "b638b829-ec12-41d1-caa5-15556868f90c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/drive/My Drive/TRANSFORMATION/data_export.zip ...\n",
            "patool: running /usr/bin/7z x -o/tmp/tmpqvf24emy -- \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\"\n",
            "patool: ... /content/drive/My Drive/TRANSFORMATION/data_export.zip extracted to `/tmp/tmpqvf24emy'.\n",
            "Dataframe 0:\n",
            "          0                   1                 2         3         4   \\\n",
            "0  row_index  second_eigenvector  original_indices  cluster2  cluster3   \n",
            "1          0  -0,657980785697483               128         0         0   \n",
            "\n",
            "         5         6          7            8       9   \\\n",
            "0  cluster4  cluster5  cluster10  cluster_id2  n_pubs   \n",
            "1         0         0          0          128   99353   \n",
            "\n",
            "                                                  10  \\\n",
            "0                                             labels   \n",
            "1  inhaler - dry powder inhaler - inhaler devices...   \n",
            "\n",
            "                                                  11  \n",
            "0                                            sources  \n",
            "1  International Journal of Pharmaceutics - Journ...  \n",
            "Dataframe 1:\n",
            "                 0                                     1\n",
            "0  for_division_id                          for_division\n",
            "1               07  Agricultural and Veterinary Sciences\n",
            "Dataframe 2:\n",
            "               0                                            1     2        3  \\\n",
            "0    institution                             institution_name     p   p_top1   \n",
            "1  grid.270301.7  Whitehead Institute for Biomedical Research  1761  253,578   \n",
            "\n",
            "         4      5             6         7                 8  \n",
            "0     tncs   mncs  pp_top_prop1  tncs_rnk  pp_top_prop1_rnk  \n",
            "1  7791,33  4,424         0,144      1071                 1  \n",
            "Dataframe 3:\n",
            "                  0              1     2     3   4   5   6   7             8   \\\n",
            "0  ur.01000000137.48  grid.412047.4  2008  2012   4   3  18  83  03 - 18 - 83   \n",
            "1  ur.01000000137.48  grid.19188.39  2009  2011   2   3  41  81  03 - 41 - 81   \n",
            "\n",
            "     9   10  \n",
            "0  2008   1  \n",
            "1  2009   1  \n",
            "Dataframe 4:\n",
            "                  0              1     2     3   4   5    6   7   \\\n",
            "0  ur.01000000010.53  grid.461843.c  2011  2021  10  11  410  64   \n",
            "1  ur.01000000010.53  grid.461843.c  2011  2021  10  11   20   5   \n",
            "\n",
            "              8     9   10  \n",
            "0  11 - 410 - 64  2011   1  \n",
            "1    11 - 20 - 5  2013   1  \n",
            "Dataframe 5:\n",
            "                   0              1     2     3   4   5   6   7           8   \\\n",
            "0  ur.010000000127.95  grid.452405.2  2007  2012   5   6   8   7  06 - 8 - 7   \n",
            "1  ur.010000000127.95  grid.452405.2  2007  2012   5   6   8   7  06 - 8 - 7   \n",
            "\n",
            "     9   10  \n",
            "0  2007   1  \n",
            "1  2009   1  \n",
            "Dataframe 6:\n",
            "                   0              1     2     3   4   5    6   7   \\\n",
            "0  ur.010000000201.99  grid.412046.5  2014  2016   2   6  379  73   \n",
            "1  ur.010000000201.99  grid.412046.5  2014  2016   2   7  379  73   \n",
            "\n",
            "              8     9   10  \n",
            "0  06 - 379 - 73  2014   1  \n",
            "1  07 - 379 - 73  2014   1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the datasets and store them into a pandas dataframe\n",
        "spectral_meso_clusters = dfs[0]\n",
        "for_division_labels = dfs[1]\n",
        "grid_ranks = dfs[2]\n",
        "trajectories_au_fourfive_skill = dfs[3]\n",
        "trajectories_au_morethanfive_skill = dfs[4]\n",
        "trajectories_au_single_skill = dfs[5]\n",
        "trajectories_au_twothree_skill = dfs[6]\n",
        "\n",
        "print(type(for_division_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR_R6_anR2IK",
        "outputId": "2c529ce4-d725-446d-830c-945de37ea3d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "pWefljUG1fsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the first row as the header\n",
        "spectral_meso_clusters.columns = spectral_meso_clusters.iloc[0]\n",
        "for_division_labels.columns = for_division_labels.iloc[0]\n",
        "grid_ranks.columns = grid_ranks.iloc[0]\n",
        "\n",
        "# Remove the first row (which is now the header)\n",
        "spectral_meso_clusters = spectral_meso_clusters[1:]\n",
        "for_division_labels = for_division_labels[1:]\n",
        "grid_ranks = grid_ranks[1:]\n",
        "\n",
        "print(spectral_meso_clusters.head())\n",
        "print(for_division_labels.head())\n",
        "print(grid_ranks.head())\n",
        "print(\"###########################################\")\n",
        "\n",
        "def convert_to_float(val):\n",
        "    if isinstance(val, str) and val.replace('.', '', 1).isdigit():\n",
        "        return float(val.replace(',', '.'))\n",
        "    return val\n",
        "\n",
        "# Apply the function to all elements of the dataframe\n",
        "grid_ranks = grid_ranks.applymap(convert_to_float)\n",
        "spectral_meso_clusters = spectral_meso_clusters.applymap(convert_to_float)\n",
        "\n",
        "print(grid_ranks.dtypes)\n",
        "print(spectral_meso_clusters.dtypes)\n",
        "print(\"###########################################\")\n",
        "\n",
        "\n",
        "from pandas.core.dtypes.dtypes import dtypes\n",
        "from numpy.core.multiarray import dtype\n",
        "\n",
        "headers = ['researcher_id', 'grid_id', 'start', 'end', 'Lenght', 'for_division_id', 'meso_field', 'spectral_cluster_id', 'concatenated_fields', 'year', 'n_pubs']\n",
        "\n",
        "# set the new column names using the list\n",
        "trajectories_au_morethanfive_skill.columns = headers\n",
        "trajectories_au_fourfive_skill.columns = headers\n",
        "trajectories_au_single_skill.columns = headers\n",
        "trajectories_au_twothree_skill.columns = headers\n",
        "\n",
        "# print the updated column names\n",
        "print(trajectories_au_morethanfive_skill.columns)\n",
        "print(trajectories_au_morethanfive_skill.dtypes)\n",
        "print(\"###########################################\")\n",
        "\n",
        "print(trajectories_au_morethanfive_skill.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHgo0KgkVhU3",
        "outputId": "6d612124-58f8-4c37-e75e-d5d06913babe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 row_index   second_eigenvector original_indices cluster2 cluster3 cluster4  \\\n",
            "1         0   -0,657980785697483              128        0        0        0   \n",
            "2         9  -0,0796790037139393              109        4        3        2   \n",
            "3         6  -0,0866583191228655              146        3        2        1   \n",
            "4         7  -0,0835526247765448              120        3        2        1   \n",
            "5         8  -0,0832388670665863              247        4        2        2   \n",
            "\n",
            "0 cluster5 cluster10 cluster_id2  n_pubs  \\\n",
            "1        0         0         128   99353   \n",
            "2        1         0         109  106502   \n",
            "3        1         0         146   91599   \n",
            "4        1         0         120  102555   \n",
            "5        1         0         247   65569   \n",
            "\n",
            "0                                             labels  \\\n",
            "1  inhaler - dry powder inhaler - inhaler devices...   \n",
            "2  CRT response - CRT device - CRT implantation -...   \n",
            "3  chiral selector - electrochromatography - plat...   \n",
            "4  household air pollution - cookstoves - energy ...   \n",
            "5  electromagnetic energy harvester - ionic polym...   \n",
            "\n",
            "0                                            sources  \n",
            "1  International Journal of Pharmaceutics - Journ...  \n",
            "2  International Journal of Cardiology - Journal ...  \n",
            "3  Journal of Chromatography A - Journal of Separ...  \n",
            "4  SSRN Electronic Journal - Energy Policy - Jour...  \n",
            "5  Proceedings of SPIE - ACS Applied Materials & ...  \n",
            "0 for_division_id                                for_division\n",
            "1              07        Agricultural and Veterinary Sciences\n",
            "2              06                         Biological Sciences\n",
            "3              12                Built Environment and Design\n",
            "4              03                           Chemical Sciences\n",
            "5              15  Commerce, Management, Tourism and Services\n",
            "0    institution                             institution_name     p   p_top1  \\\n",
            "1  grid.270301.7  Whitehead Institute for Biomedical Research  1761  253,578   \n",
            "2  grid.66859.34                              Broad Institute  8066  941,849   \n",
            "3  grid.422418.9                      American Cancer Society  1545  166,794   \n",
            "4  grid.413575.1              Howard Hughes Medical Institute  6165  572,798   \n",
            "5  grid.10306.34                    Wellcome Sanger Institute  5881    525,7   \n",
            "\n",
            "0     tncs   mncs pp_top_prop1 tncs_rnk pp_top_prop1_rnk  \n",
            "1  7791,33  4,424        0,144     1071                1  \n",
            "2  34365,1   4,26        0,117      236                2  \n",
            "3  14730,2  9,534        0,108      608                3  \n",
            "4  21460,1  3,481        0,093      437                4  \n",
            "5  20348,2   3,46        0,089      458                5  \n",
            "###########################################\n",
            "0\n",
            "institution          object\n",
            "institution_name     object\n",
            "p                   float64\n",
            "p_top1               object\n",
            "tncs                 object\n",
            "mncs                 object\n",
            "pp_top_prop1         object\n",
            "tncs_rnk            float64\n",
            "pp_top_prop1_rnk    float64\n",
            "dtype: object\n",
            "0\n",
            "row_index             float64\n",
            "second_eigenvector     object\n",
            "original_indices      float64\n",
            "cluster2              float64\n",
            "cluster3              float64\n",
            "cluster4              float64\n",
            "cluster5              float64\n",
            "cluster10             float64\n",
            "cluster_id2           float64\n",
            "n_pubs                float64\n",
            "labels                 object\n",
            "sources                object\n",
            "dtype: object\n",
            "###########################################\n",
            "Index(['researcher_id', 'grid_id', 'start', 'end', 'Lenght', 'for_division_id',\n",
            "       'meso_field', 'spectral_cluster_id', 'concatenated_fields', 'year',\n",
            "       'n_pubs'],\n",
            "      dtype='object')\n",
            "researcher_id          object\n",
            "grid_id                object\n",
            "start                   int64\n",
            "end                     int64\n",
            "Lenght                  int64\n",
            "for_division_id         int64\n",
            "meso_field              int64\n",
            "spectral_cluster_id     int64\n",
            "concatenated_fields    object\n",
            "year                    int64\n",
            "n_pubs                  int64\n",
            "dtype: object\n",
            "###########################################\n",
            "              start           end        Lenght  for_division_id  \\\n",
            "count  5.998098e+07  5.998098e+07  5.998098e+07     5.998098e+07   \n",
            "mean   2.009957e+03  2.019942e+03  9.985488e+00     8.731703e+00   \n",
            "std    3.504475e+00  2.249119e+00  3.923751e+00     3.717300e+00   \n",
            "min    2.007000e+03  2.009000e+03  2.000000e+00     1.000000e+00   \n",
            "25%    2.007000e+03  2.020000e+03  7.000000e+00     6.000000e+00   \n",
            "50%    2.008000e+03  2.021000e+03  1.100000e+01     1.000000e+01   \n",
            "75%    2.012000e+03  2.021000e+03  1.400000e+01     1.100000e+01   \n",
            "max    2.019000e+03  2.021000e+03  1.400000e+01     2.200000e+01   \n",
            "\n",
            "         meso_field  spectral_cluster_id          year        n_pubs  \n",
            "count  5.998098e+07         5.998098e+07  5.998098e+07  5.998098e+07  \n",
            "mean   1.998764e+02         4.212178e+01  2.015399e+03  1.398404e+00  \n",
            "std    1.633995e+02         3.319160e+01  4.048403e+00  1.558997e+00  \n",
            "min    0.000000e+00         0.000000e+00  2.007000e+03  1.000000e+00  \n",
            "25%    6.600000e+01         8.000000e+00  2.012000e+03  1.000000e+00  \n",
            "50%    1.570000e+02         3.800000e+01  2.016000e+03  1.000000e+00  \n",
            "75%    2.970000e+02         7.600000e+01  2.019000e+03  1.000000e+00  \n",
            "max    8.640000e+02         8.600000e+01  2.021000e+03  3.719000e+03  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_org_sequence(df):\n",
        "    # select the desired columns and drop duplicates\n",
        "    df = df[['researcher_id', 'grid_id', 'start', 'end']].drop_duplicates().reset_index(drop=True)\n",
        "    \n",
        "    # calculate the org_sequence using rank()\n",
        "    df['org_sequence'] = df.groupby('researcher_id')['start'].rank(method='dense')\n",
        "    \n",
        "    return df\n",
        "\n",
        "# calculate org_sequence for each dataframe\n",
        "sq_1_skill_df = calculate_org_sequence(trajectories_au_single_skill)\n",
        "sq_2_3_skill_df = calculate_org_sequence(trajectories_au_twothree_skill)\n",
        "sq_4_5_skill_df = calculate_org_sequence(trajectories_au_fourfive_skill)\n",
        "sq_5_or_more_skill_df = calculate_org_sequence(trajectories_au_morethanfive_skill)\n",
        "\n",
        "# merge the two dataframes on researcher_id and grid_id\n",
        "sq_1_skill_df = pd.merge(trajectories_au_single_skill, sq_1_skill_df, on=['researcher_id', 'grid_id'], how='left')\n",
        "sq_1_skill_df = sq_1_skill_df.loc[:, ~sq_1_skill_df.columns.str.endswith('_y')]\n",
        "sq_1_skill_df = sq_1_skill_df.rename(columns=lambda x: x[:-2] if x.endswith('_x') else x)\n",
        "\n",
        "sq_2_3_skill_df = pd.merge(trajectories_au_twothree_skill, sq_2_3_skill_df, on=['researcher_id', 'grid_id'], how='left')\n",
        "sq_2_3_skill_df = sq_2_3_skill_df.loc[:, ~sq_2_3_skill_df.columns.str.endswith('_y')]\n",
        "sq_2_3_skill_df = sq_2_3_skill_df.rename(columns=lambda x: x[:-2] if x.endswith('_x') else x)\n",
        "\n",
        "sq_4_5_skill_df = pd.merge(trajectories_au_fourfive_skill, sq_4_5_skill_df, on=['researcher_id', 'grid_id'], how='left')\n",
        "sq_4_5_skill_df = sq_4_5_skill_df.loc[:, ~sq_4_5_skill_df.columns.str.endswith('_y')]\n",
        "sq_4_5_skill_df = sq_4_5_skill_df.rename(columns=lambda x: x[:-2] if x.endswith('_x') else x)\n",
        "\n",
        "sq_5_or_more_skill_df = pd.merge(trajectories_au_morethanfive_skill, sq_5_or_more_skill_df, on=['researcher_id', 'grid_id'], how='left')\n",
        "sq_5_or_more_skill_df = sq_5_or_more_skill_df.loc[:, ~sq_5_or_more_skill_df.columns.str.endswith('_y')]\n",
        "sq_5_or_more_skill_df = sq_5_or_more_skill_df.rename(columns=lambda x: x[:-2] if x.endswith('_x') else x)\n",
        "\n",
        "print(sq_1_skill_df.head())\n",
        "print(len(sq_1_skill_df))\n",
        "print(len(trajectories_au_single_skill))\n",
        "\n",
        "#print(sq_1_skill_df.head(10))\n",
        "# select all rows that have org_sequence > 1\n",
        "#sq_1_skill_df_filtered = sq_1_skill_df[sq_1_skill_df['org_sequence'] > 1]\n",
        "#print(sq_1_skill_df_filtered.head(10))\n",
        "# select all rows that have researcher_id = 'ur.01000012260.80'\n",
        "#sq_1_skill_df_filtered_au = sq_1_skill_df[sq_1_skill_df['researcher_id'] == 'ur.01000012260.80']\n",
        "#print(sq_1_skill_df_filtered_au.head(10))"
      ],
      "metadata": {
        "id": "rY7dPXli-b2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks good!**"
      ],
      "metadata": {
        "id": "AKD-KDlhkmZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUJcoYl4rw94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}