{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarciaFG/scimobility/blob/main/transformation_index_for_2007_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transformative Flows Project (2007-2022)**\n",
        "**Author:** Marcia R. Ferreira (Complexity Science Hub Vienna & TU Wien)\n",
        "- **Inputs:** \n",
        "\n",
        "1.   CWTS SQL Server [dimensions_2022jun]:\n",
        "\n",
        "\n",
        "      *   Exported File:\n",
        "      *   Exported File:\n",
        "\n",
        "\n",
        "2.   CWTS Publication-level classification system: Meso-fields level [dimensions_2022jun_classification]\n",
        "3.   Dimension reduction-based clustering: Laplacian matrix contructed from meso-field level topic matrix and second eigenvector of the matrix\n",
        "4.   Dimensions database on BigQuery\n",
        "\n",
        "\n",
        "- **Outputs:**"
      ],
      "metadata": {
        "id": "y-DzlwsCdcsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization and drivers"
      ],
      "metadata": {
        "id": "vHLeNDGsdvjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-Ue500cAdbLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb20365-1446-4025-f96d-08ae8c823ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 14 07:30:08 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "#!pip install psutil\n",
        "#!pip install humanize\n",
        "#!pip install pynput\n",
        "#pip install plotly==5.4.0\n",
        "!pip install patool\n",
        "\n",
        "# main libraries\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import torch\n",
        "import nltk\n",
        "import GPUtil as GPU\n",
        "\n",
        "# plotting\n",
        "import plotly.graph_objs as go\n",
        "import plotly.io as pio\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "# Google big query\n",
        "from google.cloud import bigquery\n",
        "from google.colab import files\n",
        "%load_ext google.colab.data_table\n",
        "%load_ext google.cloud.bigquery\n",
        "\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wQDQL_QEd3xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e9c9c6-8d0b-496d-b47a-f8e640d17bce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7408 sha256=9f74f49ad969c98a9d89fbdb856dfd2317947f65d6e57a95c0a313e2ad626803\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/b5/24/fbb56595c286984f7315ee31821d6121e1b9828436021a88b3\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide your credentials to the runtime\n",
        "#from google.colab import auth\n",
        "#auth.authenticate_user()\n",
        "#print('Authenticated')\n",
        "\n",
        "# declare your project \n",
        "#project_id = \"cshdimensionstest\""
      ],
      "metadata": {
        "id": "5fJiI8ij1Wyx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data imports"
      ],
      "metadata": {
        "id": "g44G5rvngOrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" NOT RUN\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1wCFzWEAwBqH47qGQG1_-G6wPgrrs03A6'\n",
        "print(id) # Verify that you have everything\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('second_eigenvector_clustering.csv')  \n",
        "clusters = pd.read_csv('second_eigenvector_clustering.csv', sep=\",\", index_col=0) # Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "print(clusters.head(10))\n",
        "print(\"The data types are as follows:\\n\", clusters.dtypes)\n",
        "print(\"The type of object is:\\n\", type(clusters))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mF7pLxCkfsZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" NOT RUN\n",
        "# unzip the files exported from SQL Server\n",
        "#!unzip \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\"\n",
        "#!unzip \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\" > /dev/null\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qwu5HLlzYbTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "5RvVB9GJLu81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import patoolib\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Path of the zip file in Google Drive\n",
        "zip_path = \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\"\n",
        "\n",
        "# Name of the CSV file(s) inside the zip\n",
        "csv_file_names = [  \"spectral_meso_clusters.csv\"\n",
        "                  , \"for_division_labels.csv\"\n",
        "                  , \"grid_ranks.csv\"\n",
        "                  , \"trajectories_au_fourfive_skill.csv\"\n",
        "                  , \"trajectories_au_morethanfive_skill.csv\"\n",
        "                  , \"trajectories_au_single_skill.csv\"\n",
        "                  , \"trajectories_au_twothree_skill.csv\"]\n",
        "\n",
        "# Separator character to use in the CSV files\n",
        "separator = \";\"\n",
        "\n",
        "# Extract the zip file to a temporary directory\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    patoolib.extract_archive(zip_path, outdir=tmpdir)\n",
        "    \n",
        "    # Load each CSV file into its own dataframe\n",
        "    dfs = []\n",
        "    for csv_file_name in csv_file_names:\n",
        "        csv_file_path = os.path.join(tmpdir, csv_file_name)\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file_path, sep=separator, encoding='utf-8', header= None, decimal=\".\")\n",
        "            dfs.append(df)\n",
        "        except pd.errors.ParserError:\n",
        "            print(f\"Error loading {csv_file_name}: Skipping...\")\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# Print the first few rows of each dataframe\n",
        "for i, df in enumerate(dfs):\n",
        "    print(f\"Dataframe {i}:\")\n",
        "    print(df.head(2))\n",
        "print(\"###########################################\")\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# extract the datasets and store them into a pandas dataframe\n",
        "spectral_meso_clusters = dfs[0]\n",
        "for_division_labels = dfs[1]\n",
        "grid_ranks = dfs[2]\n",
        "trajectories_au_fourfive_skill = dfs[3]\n",
        "trajectories_au_morethanfive_skill = dfs[4]\n",
        "trajectories_au_single_skill = dfs[5]\n",
        "trajectories_au_twothree_skill = dfs[6]\n",
        "\n",
        "################################################################################\n",
        "\n",
        "print(type(for_division_labels))\n",
        "print(\"###########################################\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD6eLoCry8es",
        "outputId": "e81536de-9f9d-43c1-90e2-357232542665"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/drive/My Drive/TRANSFORMATION/data_export.zip ...\n",
            "patool: running /usr/bin/7z x -o/tmp/tmpes_gl7og -- \"/content/drive/My Drive/TRANSFORMATION/data_export.zip\"\n",
            "patool: ... /content/drive/My Drive/TRANSFORMATION/data_export.zip extracted to `/tmp/tmpes_gl7og'.\n",
            "Dataframe 0:\n",
            "          0                   1                 2         3         4   \\\n",
            "0  row_index  second_eigenvector  original_indices  cluster2  cluster3   \n",
            "1          0  -0,657980785697483               128         0         0   \n",
            "\n",
            "         5         6          7            8       9   \\\n",
            "0  cluster4  cluster5  cluster10  cluster_id2  n_pubs   \n",
            "1         0         0          0          128   99353   \n",
            "\n",
            "                                                  10  \\\n",
            "0                                             labels   \n",
            "1  inhaler - dry powder inhaler - inhaler devices...   \n",
            "\n",
            "                                                  11  \n",
            "0                                            sources  \n",
            "1  International Journal of Pharmaceutics - Journ...  \n",
            "Dataframe 1:\n",
            "                 0                                     1\n",
            "0  for_division_id                          for_division\n",
            "1               07  Agricultural and Veterinary Sciences\n",
            "Dataframe 2:\n",
            "               0                                            1     2        3  \\\n",
            "0    institution                             institution_name     p   p_top1   \n",
            "1  grid.270301.7  Whitehead Institute for Biomedical Research  1761  253,578   \n",
            "\n",
            "         4      5             6         7                 8  \n",
            "0     tncs   mncs  pp_top_prop1  tncs_rnk  pp_top_prop1_rnk  \n",
            "1  7791,33  4,424         0,144      1071                 1  \n",
            "Dataframe 3:\n",
            "                  0              1     2     3   4   5   6   7             8   \\\n",
            "0  ur.01000000137.48  grid.412047.4  2008  2012   4   3  18  83  03 - 18 - 83   \n",
            "1  ur.01000000137.48  grid.19188.39  2009  2011   2   3  41  81  03 - 41 - 81   \n",
            "\n",
            "     9   10  \n",
            "0  2008   1  \n",
            "1  2009   1  \n",
            "Dataframe 4:\n",
            "                  0              1     2     3   4   5    6   7   \\\n",
            "0  ur.01000000010.53  grid.461843.c  2011  2021  10  11  410  64   \n",
            "1  ur.01000000010.53  grid.461843.c  2011  2021  10  11   20   5   \n",
            "\n",
            "              8     9   10  \n",
            "0  11 - 410 - 64  2011   1  \n",
            "1    11 - 20 - 5  2013   1  \n",
            "Dataframe 5:\n",
            "                   0              1     2     3   4   5   6   7           8   \\\n",
            "0  ur.010000000127.95  grid.452405.2  2007  2012   5   6   8   7  06 - 8 - 7   \n",
            "1  ur.010000000127.95  grid.452405.2  2007  2012   5   6   8   7  06 - 8 - 7   \n",
            "\n",
            "     9   10  \n",
            "0  2007   1  \n",
            "1  2009   1  \n",
            "Dataframe 6:\n",
            "                   0              1     2     3   4   5    6   7   \\\n",
            "0  ur.010000000201.99  grid.412046.5  2014  2016   2   6  379  73   \n",
            "1  ur.010000000201.99  grid.412046.5  2014  2016   2   7  379  73   \n",
            "\n",
            "              8     9   10  \n",
            "0  06 - 379 - 73  2014   1  \n",
            "1  07 - 379 - 73  2014   1  \n",
            "###########################################\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "###########################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "pWefljUG1fsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the first row as the header\n",
        "spectral_meso_clusters.columns = spectral_meso_clusters.iloc[0]\n",
        "for_division_labels.columns = for_division_labels.iloc[0]\n",
        "grid_ranks.columns = grid_ranks.iloc[0]\n",
        "\n",
        "# Remove the first row (which is now the header)\n",
        "spectral_meso_clusters = spectral_meso_clusters[1:]\n",
        "for_division_labels = for_division_labels[1:]\n",
        "grid_ranks = grid_ranks[1:]\n",
        "\n",
        "print(spectral_meso_clusters.head())\n",
        "print(for_division_labels.head())\n",
        "print(grid_ranks.head())\n",
        "print(\"###########################################\")\n",
        "\n",
        "def convert_to_float(val):\n",
        "    if isinstance(val, str) and val.replace('.', '', 1).isdigit():\n",
        "        return float(val.replace(',', '.'))\n",
        "    return val\n",
        "\n",
        "# Apply the function to all elements of the dataframe\n",
        "grid_ranks = grid_ranks.applymap(convert_to_float)\n",
        "spectral_meso_clusters = spectral_meso_clusters.applymap(convert_to_float)\n",
        "\n",
        "print(grid_ranks.dtypes)\n",
        "print(spectral_meso_clusters.dtypes)\n",
        "print(\"###########################################\")\n",
        "\n",
        "\n",
        "from pandas.core.dtypes.dtypes import dtypes\n",
        "from numpy.core.multiarray import dtype\n",
        "\n",
        "headers = ['researcher_id', 'grid_id', 'start', 'end', 'Lenght', 'for_division_id', 'meso_field', 'spectral_cluster_id', 'concatenated_fields', 'year', 'n_pubs']\n",
        "\n",
        "# set the new column names using the list\n",
        "trajectories_au_morethanfive_skill.columns = headers\n",
        "trajectories_au_fourfive_skill.columns = headers\n",
        "trajectories_au_single_skill.columns = headers\n",
        "trajectories_au_twothree_skill.columns = headers\n",
        "\n",
        "# print the updated column names\n",
        "print(trajectories_au_morethanfive_skill.columns)\n",
        "print(trajectories_au_morethanfive_skill.dtypes)\n",
        "print(\"###########################################\")\n",
        "\n",
        "print(trajectories_au_morethanfive_skill.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHgo0KgkVhU3",
        "outputId": "7b383471-50bf-4ac0-9d19-a112cf42079d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 row_index   second_eigenvector original_indices cluster2 cluster3 cluster4  \\\n",
            "1         0   -0,657980785697483              128        0        0        0   \n",
            "2         9  -0,0796790037139393              109        4        3        2   \n",
            "3         6  -0,0866583191228655              146        3        2        1   \n",
            "4         7  -0,0835526247765448              120        3        2        1   \n",
            "5         8  -0,0832388670665863              247        4        2        2   \n",
            "\n",
            "0 cluster5 cluster10 cluster_id2  n_pubs  \\\n",
            "1        0         0         128   99353   \n",
            "2        1         0         109  106502   \n",
            "3        1         0         146   91599   \n",
            "4        1         0         120  102555   \n",
            "5        1         0         247   65569   \n",
            "\n",
            "0                                             labels  \\\n",
            "1  inhaler - dry powder inhaler - inhaler devices...   \n",
            "2  CRT response - CRT device - CRT implantation -...   \n",
            "3  chiral selector - electrochromatography - plat...   \n",
            "4  household air pollution - cookstoves - energy ...   \n",
            "5  electromagnetic energy harvester - ionic polym...   \n",
            "\n",
            "0                                            sources  \n",
            "1  International Journal of Pharmaceutics - Journ...  \n",
            "2  International Journal of Cardiology - Journal ...  \n",
            "3  Journal of Chromatography A - Journal of Separ...  \n",
            "4  SSRN Electronic Journal - Energy Policy - Jour...  \n",
            "5  Proceedings of SPIE - ACS Applied Materials & ...  \n",
            "0 for_division_id                                for_division\n",
            "1              07        Agricultural and Veterinary Sciences\n",
            "2              06                         Biological Sciences\n",
            "3              12                Built Environment and Design\n",
            "4              03                           Chemical Sciences\n",
            "5              15  Commerce, Management, Tourism and Services\n",
            "0    institution                             institution_name     p   p_top1  \\\n",
            "1  grid.270301.7  Whitehead Institute for Biomedical Research  1761  253,578   \n",
            "2  grid.66859.34                              Broad Institute  8066  941,849   \n",
            "3  grid.422418.9                      American Cancer Society  1545  166,794   \n",
            "4  grid.413575.1              Howard Hughes Medical Institute  6165  572,798   \n",
            "5  grid.10306.34                    Wellcome Sanger Institute  5881    525,7   \n",
            "\n",
            "0     tncs   mncs pp_top_prop1 tncs_rnk pp_top_prop1_rnk  \n",
            "1  7791,33  4,424        0,144     1071                1  \n",
            "2  34365,1   4,26        0,117      236                2  \n",
            "3  14730,2  9,534        0,108      608                3  \n",
            "4  21460,1  3,481        0,093      437                4  \n",
            "5  20348,2   3,46        0,089      458                5  \n",
            "###########################################\n",
            "0\n",
            "institution          object\n",
            "institution_name     object\n",
            "p                   float64\n",
            "p_top1               object\n",
            "tncs                 object\n",
            "mncs                 object\n",
            "pp_top_prop1         object\n",
            "tncs_rnk            float64\n",
            "pp_top_prop1_rnk    float64\n",
            "dtype: object\n",
            "0\n",
            "row_index             float64\n",
            "second_eigenvector     object\n",
            "original_indices      float64\n",
            "cluster2              float64\n",
            "cluster3              float64\n",
            "cluster4              float64\n",
            "cluster5              float64\n",
            "cluster10             float64\n",
            "cluster_id2           float64\n",
            "n_pubs                float64\n",
            "labels                 object\n",
            "sources                object\n",
            "dtype: object\n",
            "###########################################\n",
            "Index(['researcher_id', 'grid_id', 'start', 'end', 'Lenght', 'for_division_id',\n",
            "       'meso_field', 'spectral_cluster_id', 'concatenated_fields', 'year',\n",
            "       'n_pubs'],\n",
            "      dtype='object')\n",
            "researcher_id          object\n",
            "grid_id                object\n",
            "start                   int64\n",
            "end                     int64\n",
            "Lenght                  int64\n",
            "for_division_id         int64\n",
            "meso_field              int64\n",
            "spectral_cluster_id     int64\n",
            "concatenated_fields    object\n",
            "year                    int64\n",
            "n_pubs                  int64\n",
            "dtype: object\n",
            "###########################################\n",
            "              start           end        Lenght  for_division_id  \\\n",
            "count  5.998098e+07  5.998098e+07  5.998098e+07     5.998098e+07   \n",
            "mean   2.009957e+03  2.019942e+03  9.985488e+00     8.731703e+00   \n",
            "std    3.504475e+00  2.249119e+00  3.923751e+00     3.717300e+00   \n",
            "min    2.007000e+03  2.009000e+03  2.000000e+00     1.000000e+00   \n",
            "25%    2.007000e+03  2.020000e+03  7.000000e+00     6.000000e+00   \n",
            "50%    2.008000e+03  2.021000e+03  1.100000e+01     1.000000e+01   \n",
            "75%    2.012000e+03  2.021000e+03  1.400000e+01     1.100000e+01   \n",
            "max    2.019000e+03  2.021000e+03  1.400000e+01     2.200000e+01   \n",
            "\n",
            "         meso_field  spectral_cluster_id          year        n_pubs  \n",
            "count  5.998098e+07         5.998098e+07  5.998098e+07  5.998098e+07  \n",
            "mean   1.998764e+02         4.212178e+01  2.015399e+03  1.398404e+00  \n",
            "std    1.633995e+02         3.319160e+01  4.048403e+00  1.558997e+00  \n",
            "min    0.000000e+00         0.000000e+00  2.007000e+03  1.000000e+00  \n",
            "25%    6.600000e+01         8.000000e+00  2.012000e+03  1.000000e+00  \n",
            "50%    1.570000e+02         3.800000e+01  2.016000e+03  1.000000e+00  \n",
            "75%    2.970000e+02         7.600000e+01  2.019000e+03  1.000000e+00  \n",
            "max    8.640000e+02         8.600000e+01  2.021000e+03  3.719000e+03  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_org_sequence(df):\n",
        "    # select the desired columns and drop duplicates\n",
        "    df = df[['researcher_id', 'grid_id', 'for_division_id', 'start', 'end']].drop_duplicates().reset_index(drop=True)\n",
        "    \n",
        "    # concatenate start, end, and for_division_id columns\n",
        "    df['concatenated'] = df['start'].astype(str) + '_' + df['end'].astype(str) + '_' + df['for_division_id'].astype(str)\n",
        "    \n",
        "    # calculate the org_sequence using rank() method that considers concatenated column\n",
        "    df['org_sequence'] = df.groupby('researcher_id')['concatenated'].rank(method='dense')\n",
        "    \n",
        "    # drop the concatenated column\n",
        "    df = df.drop('concatenated', axis=1)\n",
        "    \n",
        "    # return the researcher_id, grid_id, for_division_id, and org_sequence columns\n",
        "    return df[['researcher_id', 'grid_id', 'for_division_id', 'org_sequence']]\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def process_dataframe(df, org_seq_df):\n",
        "    # merge the dataframes on researcher_id and grid_id\n",
        "    merged_df = pd.merge(df, org_seq_df, on=['researcher_id', 'grid_id'], how='left')\n",
        "    merged_df = merged_df.loc[:, ~merged_df.columns.str.endswith('_y')]\n",
        "    merged_df = merged_df.rename(columns=lambda x: x[:-2] if x.endswith('_x') else x)\n",
        "\n",
        "    # concatenate two columns\n",
        "    merged_df['concatenated_2'] = merged_df['for_division_id'].astype(str) + ' - ' + merged_df['spectral_cluster_id'].astype(str)\n",
        "\n",
        "    # select and aggregate columns\n",
        "    selected_cols = ['researcher_id', 'grid_id', 'for_division_id', 'concatenated_2', 'org_sequence', 'n_pubs']\n",
        "    selected_df = merged_df[selected_cols].drop_duplicates().reset_index(drop=True)\n",
        "    aggregated_df = selected_df.groupby(['researcher_id', 'grid_id','for_division_id', 'concatenated_2','org_sequence']).sum().reset_index()\n",
        "\n",
        "    return aggregated_df\n",
        "\n",
        "################################################################################\n",
        "\n",
        "sq_1_skill_df = process_dataframe(trajectories_au_single_skill, calculate_org_sequence(trajectories_au_single_skill))\n",
        "sq_2_3_skill_df = process_dataframe(trajectories_au_twothree_skill, calculate_org_sequence(trajectories_au_twothree_skill))\n",
        "sq_4_5_skill_df = process_dataframe(trajectories_au_fourfive_skill, calculate_org_sequence(trajectories_au_fourfive_skill))\n",
        "sq_5_or_more_skill_df = process_dataframe(trajectories_au_morethanfive_skill, calculate_org_sequence(trajectories_au_morethanfive_skill))\n",
        "\n",
        "################################################################################\n",
        "\n",
        "print(sq_1_skill_df.head())\n",
        "print(len(sq_1_skill_df))\n",
        "print(len(trajectories_au_single_skill))"
      ],
      "metadata": {
        "id": "jHhghZlE2lBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks good!**"
      ],
      "metadata": {
        "id": "AKD-KDlhkmZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = sq_2_3_skill_df[sq_2_3_skill_df[\"researcher_id\"] == 'ur.010000002457.43']"
      ],
      "metadata": {
        "id": "DzP1McQRQeVs"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine similarity scores"
      ],
      "metadata": {
        "id": "A_0bWaHt4Z61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# attempt 1\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(df):\n",
        "    df = df.sort_values(['researcher_id', 'org_sequence'])\n",
        "\n",
        "    unique_researchers = df['researcher_id'].drop_duplicates()\n",
        "\n",
        "    results = pd.DataFrame(columns=['researcher_id', 'prev_org_sequence', 'next_org_sequence', 'prev_grid_id', 'next_grid_id', 'prev_for_division_id','next_for_division_id', 'cosine_similarity'])\n",
        "\n",
        "    for researcher_id in unique_researchers:\n",
        "        researcher_data = df[df['researcher_id'] == researcher_id]\n",
        "        max_org_sequence = researcher_data['org_sequence'].max()\n",
        "\n",
        "        for org_sequence in range(1, int(max_org_sequence)):\n",
        "            prev_data = researcher_data[researcher_data['org_sequence'] == org_sequence]\n",
        "            next_data = researcher_data[researcher_data['org_sequence'] == org_sequence + 1]\n",
        "\n",
        "            if not prev_data.empty and not next_data.empty:\n",
        "                pivot_prev = prev_data.pivot_table(values='n_pubs', index='org_sequence', columns='concatenated_2', aggfunc=np.sum, fill_value=0)\n",
        "                pivot_next = next_data.pivot_table(values='n_pubs', index='org_sequence', columns='concatenated_2', aggfunc=np.sum, fill_value=0)\n",
        "\n",
        "                merged_pivot = pd.concat([pivot_prev, pivot_next], axis=0).fillna(0)\n",
        "\n",
        "                prev_row = merged_pivot.iloc[[0]]\n",
        "                next_row = merged_pivot.iloc[[1]]\n",
        "\n",
        "                cosine_sim = cosine_similarity(prev_row, next_row)[0][0]\n",
        "\n",
        "                result_row = {\n",
        "                    'researcher_id': researcher_id, \n",
        "                    'prev_org_sequence': org_sequence, \n",
        "                    'next_org_sequence': org_sequence + 1,\n",
        "                    'prev_grid_id': prev_data['grid_id'].values[0], \n",
        "                    'next_grid_id': next_data['grid_id'].values[0], \n",
        "                    'prev_for_division_id': prev_data['for_division_id'].values[0], \n",
        "                    'next_for_division_id': next_data['for_division_id'].values[0],\n",
        "                    'cosine_similarity': cosine_sim\n",
        "                }\n",
        "                results = results.append(result_row, ignore_index=True)\n",
        "\n",
        "    return results\n",
        "\n",
        "test = calculate_cosine_similarity(df_test)\n",
        "print(test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PzJc54_g4Y30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attempt 2\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(df):\n",
        "    df = df.sort_values(['researcher_id', 'org_sequence'])\n",
        "\n",
        "    unique_researchers = df['researcher_id'].drop_duplicates()\n",
        "\n",
        "    results = pd.DataFrame(columns=['researcher_id', 'prev_org_sequence', 'next_org_sequence', 'prev_grid_id', 'next_grid_id', 'prev_for_division_id','next_for_division_id', 'cosine_similarity'])\n",
        "\n",
        "    for researcher_id in unique_researchers:\n",
        "        researcher_data = df[df['researcher_id'] == researcher_id]\n",
        "        max_org_sequence = researcher_data['org_sequence'].max()\n",
        "        unique_for_division_ids = researcher_data['for_division_id'].drop_duplicates()\n",
        "\n",
        "        for for_division_id in unique_for_division_ids:\n",
        "            division_data = researcher_data[researcher_data['for_division_id'] == for_division_id]\n",
        "\n",
        "            for org_sequence in range(1, int(max_org_sequence)):\n",
        "                prev_data = division_data[division_data['org_sequence'] == org_sequence]\n",
        "                next_data = division_data[division_data['org_sequence'] == org_sequence + 1]\n",
        "\n",
        "                if not prev_data.empty and not next_data.empty:\n",
        "                    pivot_prev = prev_data.pivot_table(values='n_pubs', index='org_sequence', columns='concatenated_2', aggfunc=np.sum, fill_value=0)\n",
        "                    pivot_next = next_data.pivot_table(values='n_pubs', index='org_sequence', columns='concatenated_2', aggfunc=np.sum, fill_value=0)\n",
        "\n",
        "                    merged_pivot = pd.concat([pivot_prev, pivot_next], axis=0).fillna(0)\n",
        "\n",
        "                    prev_row = merged_pivot.iloc[[0]]\n",
        "                    next_row = merged_pivot.iloc[[1]]\n",
        "\n",
        "                    cosine_sim = cosine_similarity(prev_row, next_row)[0][0]\n",
        "\n",
        "                    result_row = {\n",
        "                        'researcher_id': researcher_id, \n",
        "                        'prev_org_sequence': org_sequence, \n",
        "                        'next_org_sequence': org_sequence + 1,\n",
        "                        'prev_grid_id': prev_data['grid_id'].values[0], \n",
        "                        'next_grid_id': next_data['grid_id'].values[0], \n",
        "                        'prev_for_division_id': prev_data['for_division_id'].values[0], \n",
        "                        'next_for_division_id': next_data['for_division_id'].values[0],\n",
        "                        'cosine_similarity': cosine_sim\n",
        "                    }\n",
        "                    results = results.append(result_row, ignore_index=True)\n",
        "\n",
        "    return results\n",
        "    \n",
        "test = calculate_cosine_similarity(df_test)\n",
        "#print(test)\n"
      ],
      "metadata": {
        "id": "7Kpbww32aZAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attempt 3\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(df):\n",
        "    df = df.sort_values(['researcher_id', 'org_sequence'])\n",
        "\n",
        "    unique_researchers = df['researcher_id'].drop_duplicates()\n",
        "\n",
        "    results = pd.DataFrame(columns=['researcher_id', 'prev_org_sequence', 'next_org_sequence', 'prev_grid_id', 'next_grid_id', 'prev_for_division_id','next_for_division_id', 'cosine_similarity'])\n",
        "\n",
        "    for researcher_id in unique_researchers:\n",
        "        researcher_data = df[df['researcher_id'] == researcher_id]\n",
        "        max_org_sequence = researcher_data['org_sequence'].max()\n",
        "\n",
        "        for org_sequence in range(1, int(max_org_sequence)):\n",
        "            prev_data = researcher_data[researcher_data['org_sequence'] == org_sequence]\n",
        "            next_data = researcher_data[researcher_data['org_sequence'] == org_sequence + 1]\n",
        "\n",
        "            if not prev_data.empty and not next_data.empty:\n",
        "                unique_for_division_ids = prev_data['for_division_id'].drop_duplicates()\n",
        "\n",
        "                for for_division_id in unique_for_division_ids:\n",
        "                    filtered_prev_data = prev_data[prev_data['for_division_id'] == for_division_id]\n",
        "                    filtered_next_data = next_data[next_data['for_division_id'] == for_division_id]\n",
        "\n",
        "                    if not filtered_prev_data.empty and not filtered_next_data.empty:\n",
        "                        pivot_prev = filtered_prev_data.pivot_table(values='n_pubs', index='org_sequence', columns='concatenated_2', aggfunc=np.sum, fill_value=0)\n",
        "                        pivot_next = filtered_next_data.pivot_table(values='n_pubs', index='org_sequence', columns='concatenated_2', aggfunc=np.sum, fill_value=0)\n",
        "\n",
        "                        merged_pivot = pd.concat([pivot_prev, pivot_next], axis=0).fillna(0)\n",
        "\n",
        "                        prev_row = merged_pivot.iloc[[0]]\n",
        "                        next_row = merged_pivot.iloc[[1]]\n",
        "\n",
        "                        cosine_sim = cosine_similarity(prev_row, next_row)[0][0]\n",
        "\n",
        "                        result_row = {\n",
        "                            'researcher_id': researcher_id, \n",
        "                            'prev_org_sequence': org_sequence, \n",
        "                            'next_org_sequence': org_sequence + 1,\n",
        "                            'prev_grid_id': filtered_prev_data['grid_id'].values[0], \n",
        "                            'next_grid_id': filtered_next_data['grid_id'].values[0], \n",
        "                            'prev_for_division_id': for_division_id, \n",
        "                            'next_for_division_id': for_division_id,\n",
        "                            'cosine_similarity': cosine_sim\n",
        "                        }\n",
        "                        results = results.append(result_row, ignore_index=True)\n",
        "\n",
        "    return results\n",
        "\n",
        "test = calculate_cosine_similarity(df_test)\n",
        "print(test)\n"
      ],
      "metadata": {
        "id": "DdL-9253csw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attempt 4\n",
        "# attempt 5\n",
        "def get_cosine_similarity(researcher_df, prev_org_seq, next_org_seq, for_division_id):\n",
        "    prev_df = researcher_df[(researcher_df['org_sequence'] == prev_org_seq) & (researcher_df['for_division_id'] == for_division_id)]\n",
        "    next_df = researcher_df[(researcher_df['org_sequence'] == next_org_seq) & (researcher_df['for_division_id'] == for_division_id)]\n",
        "\n",
        "    label_to_index = {label: idx for idx, label in enumerate(sorted(researcher_df['concatenated_2'].unique()))}\n",
        "    \n",
        "    prev_vector = np.zeros(len(label_to_index))\n",
        "    next_vector = np.zeros(len(label_to_index))\n",
        "\n",
        "    for _, row in prev_df.iterrows():\n",
        "        code = row['concatenated_2']\n",
        "        prev_vector[label_to_index[code]] = row['n_pubs']\n",
        "\n",
        "    for _, row in next_df.iterrows():\n",
        "        code = row['concatenated_2']\n",
        "        next_vector[label_to_index[code]] = row['n_pubs']\n",
        "    \n",
        "    print(\"prev_vector:\", prev_vector)\n",
        "    print(\"next_vector:\", next_vector)\n",
        "\n",
        "    cosine_similarity = np.dot(prev_vector, next_vector) / (np.linalg.norm(prev_vector) * np.linalg.norm(next_vector))\n",
        "    print(\"cosine_similarity:\", cosine_similarity)\n",
        "    return cosine_similarity\n",
        "\n",
        "results = []\n",
        "\n",
        "for researcher_id in df_test['researcher_id'].unique():\n",
        "    researcher_df = df_test[df_test['researcher_id'] == researcher_id]\n",
        "    org_sequences = sorted(researcher_df['org_sequence'].unique())\n",
        "\n",
        "    for idx in range(len(org_sequences) - 1):\n",
        "        prev_org_seq = org_sequences[idx]\n",
        "        next_org_seq = org_sequences[idx + 1]\n",
        "\n",
        "        for for_division_id in researcher_df['for_division_id'].unique():\n",
        "            prev_df = researcher_df[(researcher_df['org_sequence'] == prev_org_seq) & (researcher_df['for_division_id'] == for_division_id)]\n",
        "            next_df = researcher_df[(researcher_df['org_sequence'] == next_org_seq) & (researcher_df['for_division_id'] == for_division_id)]\n",
        "\n",
        "            if not prev_df.empty and not next_df.empty:\n",
        "                prev_grid_id = prev_df['grid_id'].iloc[0]\n",
        "                next_grid_id = next_df['grid_id'].iloc[0]\n",
        "\n",
        "                cosine_similarity = get_cosine_similarity(researcher_df, prev_org_seq, next_org_seq, for_division_id)\n",
        "\n",
        "                results.append({\n",
        "                    'researcher_id': researcher_id,\n",
        "                    'prev_org_sequence': prev_org_seq,\n",
        "                    'next_org_sequence': next_org_seq,\n",
        "                    'prev_grid_id': prev_grid_id,\n",
        "                    'next_grid_id': next_grid_id,\n",
        "                    'prev_for_division_id': for_division_id,\n",
        "                    'next_for_division_id': for_division_id,\n",
        "                    'cosine_similarity': cosine_similarity\n",
        "                })\n",
        "\n",
        "output_table = pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SWBnBKyhBsS",
        "outputId": "993e1cab-4f76-4659-ed9b-c347f4ae2313"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prev_vector: [0. 0. 1. 0. 7. 0. 0. 0.]\n",
            "prev_vector: [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "prev_vector: [ 0.  0.  0.  0. 17.  0.  0.  0.]\n",
            "prev_vector: [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "prev_vector: [0. 0. 0. 1. 4. 0. 0. 0.]\n",
            "prev_vector: [0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_table.head(100)\n",
        "print(prev_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "8UelZrhFW5mM",
        "outputId": "125e2743-8c19-489e-e88c-d5af598251d6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-30e1ea6b7043>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prev_vector' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sq_2_3_skill_df[sq_2_3_skill_df[\"researcher_id\"] == 'ur.010000002457.43']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "qbwz2GXlXD5y",
        "outputId": "04d7c270-a742-4b5a-81d6-2da63a2b4961"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         researcher_id        grid_id  for_division_id concatenated_2  \\\n",
              "17  ur.010000002457.43  grid.410726.6                4         4 - 85   \n",
              "18  ur.010000002457.43  grid.458451.9                4          4 - 2   \n",
              "19  ur.010000002457.43  grid.458451.9                4         4 - 85   \n",
              "20  ur.010000002457.43  grid.458451.9                6         6 - 85   \n",
              "21  ur.010000002457.43  grid.458451.9                7         7 - 85   \n",
              "22  ur.010000002457.43  grid.496923.3                3         3 - 85   \n",
              "23  ur.010000002457.43  grid.496923.3                4          4 - 5   \n",
              "24  ur.010000002457.43  grid.496923.3                4         4 - 85   \n",
              "25  ur.010000002457.43  grid.496923.3                5         5 - 85   \n",
              "26  ur.010000002457.43  grid.496923.3                6         6 - 85   \n",
              "27  ur.010000002457.43  grid.511503.3                4         4 - 85   \n",
              "28  ur.010000002457.43  grid.64337.35                4         4 - 85   \n",
              "29  ur.010000002457.43    grid.9227.e                4         4 - 85   \n",
              "30  ur.010000002457.43    grid.9227.e                6         6 - 85   \n",
              "31  ur.010000002457.43    grid.9227.e               21        21 - 85   \n",
              "\n",
              "    org_sequence  n_pubs  \n",
              "17           4.0       1  \n",
              "18           1.0       1  \n",
              "19           1.0       7  \n",
              "20           1.0       1  \n",
              "21           1.0       1  \n",
              "22           3.0       1  \n",
              "23           3.0       1  \n",
              "24           3.0       9  \n",
              "25           3.0       1  \n",
              "26           3.0       1  \n",
              "27           5.0       3  \n",
              "28           3.0       4  \n",
              "29           2.0      17  \n",
              "30           2.0       1  \n",
              "31           2.0       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c7a6a36-e163-430d-bcb0-cf626ebb830c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>researcher_id</th>\n",
              "      <th>grid_id</th>\n",
              "      <th>for_division_id</th>\n",
              "      <th>concatenated_2</th>\n",
              "      <th>org_sequence</th>\n",
              "      <th>n_pubs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.410726.6</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 85</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.458451.9</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.458451.9</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 85</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.458451.9</td>\n",
              "      <td>6</td>\n",
              "      <td>6 - 85</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.458451.9</td>\n",
              "      <td>7</td>\n",
              "      <td>7 - 85</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.496923.3</td>\n",
              "      <td>3</td>\n",
              "      <td>3 - 85</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.496923.3</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.496923.3</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 85</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.496923.3</td>\n",
              "      <td>5</td>\n",
              "      <td>5 - 85</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.496923.3</td>\n",
              "      <td>6</td>\n",
              "      <td>6 - 85</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.511503.3</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 85</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.64337.35</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 85</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.9227.e</td>\n",
              "      <td>4</td>\n",
              "      <td>4 - 85</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.9227.e</td>\n",
              "      <td>6</td>\n",
              "      <td>6 - 85</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>ur.010000002457.43</td>\n",
              "      <td>grid.9227.e</td>\n",
              "      <td>21</td>\n",
              "      <td>21 - 85</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c7a6a36-e163-430d-bcb0-cf626ebb830c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c7a6a36-e163-430d-bcb0-cf626ebb830c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c7a6a36-e163-430d-bcb0-cf626ebb830c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 17,\n            'f': \"17\",\n        },\n\"ur.010000002457.43\",\n\"grid.410726.6\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 85\",\n{\n            'v': 4.0,\n            'f': \"4.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"ur.010000002457.43\",\n\"grid.458451.9\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 2\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"ur.010000002457.43\",\n\"grid.458451.9\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 85\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 7,\n            'f': \"7\",\n        }],\n [{\n            'v': 20,\n            'f': \"20\",\n        },\n\"ur.010000002457.43\",\n\"grid.458451.9\",\n{\n            'v': 6,\n            'f': \"6\",\n        },\n\"6 - 85\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 21,\n            'f': \"21\",\n        },\n\"ur.010000002457.43\",\n\"grid.458451.9\",\n{\n            'v': 7,\n            'f': \"7\",\n        },\n\"7 - 85\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 22,\n            'f': \"22\",\n        },\n\"ur.010000002457.43\",\n\"grid.496923.3\",\n{\n            'v': 3,\n            'f': \"3\",\n        },\n\"3 - 85\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 23,\n            'f': \"23\",\n        },\n\"ur.010000002457.43\",\n\"grid.496923.3\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 5\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 24,\n            'f': \"24\",\n        },\n\"ur.010000002457.43\",\n\"grid.496923.3\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 85\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 9,\n            'f': \"9\",\n        }],\n [{\n            'v': 25,\n            'f': \"25\",\n        },\n\"ur.010000002457.43\",\n\"grid.496923.3\",\n{\n            'v': 5,\n            'f': \"5\",\n        },\n\"5 - 85\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 26,\n            'f': \"26\",\n        },\n\"ur.010000002457.43\",\n\"grid.496923.3\",\n{\n            'v': 6,\n            'f': \"6\",\n        },\n\"6 - 85\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 27,\n            'f': \"27\",\n        },\n\"ur.010000002457.43\",\n\"grid.511503.3\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 85\",\n{\n            'v': 5.0,\n            'f': \"5.0\",\n        },\n{\n            'v': 3,\n            'f': \"3\",\n        }],\n [{\n            'v': 28,\n            'f': \"28\",\n        },\n\"ur.010000002457.43\",\n\"grid.64337.35\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 85\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 4,\n            'f': \"4\",\n        }],\n [{\n            'v': 29,\n            'f': \"29\",\n        },\n\"ur.010000002457.43\",\n\"grid.9227.e\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n\"4 - 85\",\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n{\n            'v': 17,\n            'f': \"17\",\n        }],\n [{\n            'v': 30,\n            'f': \"30\",\n        },\n\"ur.010000002457.43\",\n\"grid.9227.e\",\n{\n            'v': 6,\n            'f': \"6\",\n        },\n\"6 - 85\",\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 31,\n            'f': \"31\",\n        },\n\"ur.010000002457.43\",\n\"grid.9227.e\",\n{\n            'v': 21,\n            'f': \"21\",\n        },\n\"21 - 85\",\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n{\n            'v': 1,\n            'f': \"1\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"researcher_id\"], [\"string\", \"grid_id\"], [\"number\", \"for_division_id\"], [\"string\", \"concatenated_2\"], [\"number\", \"org_sequence\"], [\"number\", \"n_pubs\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity = dot_product(v1, v2) / (magnitude(v1) * magnitude(v2))\n",
        "\n",
        "dot_product(v1, v2) = (1 * 0) + (7 * 13) + (0 * 1) = 0 + 91 + 0 = 91\n",
        "magnitude(v1) = sqrt(1^2 + 7^2 + 0^2) = sqrt(1 + 49 + 0) = sqrt(50)\n",
        "magnitude(v2) = sqrt(0^2 + 13^2 + 1^2) = sqrt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "eWgnbS43fjA6",
        "outputId": "2d7bf68a-7b06-42d8-930d-d20993565999"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-c2f0b093f241>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dot_product(v1, v2) = (1 * 0) + (7 * 13) + (0 * 1) = 0 + 91 + 0 = 91\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
          ]
        }
      ]
    }
  ]
}